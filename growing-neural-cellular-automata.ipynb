{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "# just for TF to see a single GPU in the server\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# min-max steps the network will be required to learn \n",
    "N = (300, 400)\n",
    "# number fo parallel generation since it's stochastic \n",
    "BATCH_SIZE = 6\n",
    "# n. of channels (RGBa + N others for information transmission)\n",
    "OUT_DIMS = 32\n",
    "# trainin epochs\n",
    "EPOCHS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path of the image\n",
    "image_path = \"symbols/emojismall.png\"\n",
    "# import the image\n",
    "image = np.array(Image.open(image_path), dtype = float)[None, ...]\n",
    "# normalize the imported image\n",
    "image = image/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CA (tf.keras.Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        # define Sobel filters and prepare for depthwise convolution \n",
    "        self.sobel_x = tf.convert_to_tensor([\n",
    "            [-1, 0, 1],\n",
    "            [-2, 0, 2],\n",
    "            [-1, 0, 1]\n",
    "        ], dtype = tf.float32)[..., None]\n",
    "        self.sobel_y = tf.convert_to_tensor([\n",
    "            [-1, -2, -1],\n",
    "            [0, 0, 0],\n",
    "            [1, 2, 1]\n",
    "        ], dtype = tf.float32)[..., None]\n",
    "\n",
    "        self.sobel_y = tf.repeat(self.sobel_y, OUT_DIMS, axis = -1)[..., None]\n",
    "        self.sobel_x = tf.repeat(self.sobel_x, OUT_DIMS, axis = -1)[..., None]\n",
    "\n",
    "        # layers of the network\n",
    "        self.batch_norm1 = tf.keras.layers.BatchNormalization()\n",
    "        #self.batch_norm2 = tf.keras.layers.BatchNormalization()\n",
    "        self.batch_norm3 = tf.keras.layers.BatchNormalization()\n",
    "        self.convlayer1 = tf.keras.layers.Conv2D(128, 1, padding = \"SAME\", activation = tf.nn.leaky_relu)\n",
    "        #self.convlayer2 = tf.keras.layers.Conv2D(128, 1, padding = \"SAME\", activation = tf.nn.leaky_relu)\n",
    "        self.convlayer3 = tf.keras.layers.Conv2D(OUT_DIMS, 1, padding = \"SAME\", activation = \"linear\",\n",
    "                                                kernel_initializer=tf.initializers.zeros(),\n",
    "                                                bias_initializer=tf.initializers.zeros())\n",
    "        self.maxpool = tf.keras.layers.MaxPooling2D((3,3), 1, padding= \"SAME\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # apply Sobel filters\n",
    "        grad_x = tf.nn.depthwise_conv2d(inputs, self.sobel_x, strides = [1, 1, 1, 1], padding = \"SAME\")\n",
    "        grad_y = tf.nn.depthwise_conv2d(inputs, self.sobel_y, strides = [1, 1, 1, 1], padding = \"SAME\")\n",
    "\n",
    "        # concatenate to create the information of each cell\n",
    "        result = tf.concat((inputs, grad_x, grad_y), axis=-1)\n",
    "\n",
    "        # forward pass of the ffnn-per-pixel\n",
    "        result = self.batch_norm1(result)\n",
    "        result = self.convlayer1(result)\n",
    "        #result = self.batch_norm2(result)\n",
    "        #result = self.convlayer2(result)\n",
    "        result = self.batch_norm3(result)\n",
    "        result = self.convlayer3(result)\n",
    "\n",
    "        # randomly remove 20% of the pixels\n",
    "        rand_mask = tf.random.uniform(tf.shape(inputs)[0:3].numpy().tolist() + [1]) < 0.8\n",
    "        rand_mask = tf.cast(rand_mask, dtype = tf.float32)\n",
    "        rand_mask = tf.repeat(rand_mask, tf.shape(inputs)[-1], axis=-1)\n",
    "\n",
    "        result = result * rand_mask\n",
    "        result = result + inputs\n",
    "\n",
    "        # 0-out the pixels that are predicted to be dead \n",
    "        # TODO: gradient won't flow, maybe better to use estimators or reinforcement learning\n",
    "        alive = self.maxpool(result[:,:,:,3:4]) > 0.1\n",
    "        alive = tf.cast(alive, dtype = tf.float32)\n",
    "        alive = tf.repeat(alive, tf.shape(inputs)[-1], axis=-1)\n",
    "\n",
    "        result = result * alive\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the initial image and set the central pixel to 1\n",
    "empty_image = np.zeros((BATCH_SIZE, )+ image.shape[1:3]+(OUT_DIMS,))\n",
    "empty_image[:, empty_image.shape[1]//2, empty_image.shape[2]//2, 3:]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = CA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.legacy.Adam(learning_rate=1e-4)\n",
    "\n",
    "# training loop, store the model every 10 epochs\n",
    "for i in range(EPOCHS):\n",
    "    with tf.GradientTape() as tape:\n",
    "        current_image = np.copy(empty_image)\n",
    "        for j in range(random.randint(*N)):\n",
    "            current_image = model(current_image)\n",
    "        current_image = current_image[:, :, :, 0:4]\n",
    "\n",
    "        loss = tf.reduce_mean((current_image-image)**2)\n",
    "    grad = tape.gradient(loss,model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grad, model.trainable_weights))\n",
    "    \n",
    "    if (i+1) % 10 == 0:\n",
    "        print(f\" epoch {i} - loss {loss}\")\n",
    "        model.save_weights(f\"./checkpoints/{i}/checkpoint\"\"\")\n",
    "        model.save(f\"./checkpoints/{i}/my_model.keras\")\n",
    "    else:\n",
    "        print(\"*\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fc8f0388e20>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_ghost = CA()\n",
    "m_ghost.load_weights(\"checkpoints-ghost/final/checkpoint\")\n",
    "\n",
    "m_emoji = CA()\n",
    "m_emoji.load_weights(\"checkpoints-emoji/final/checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create images of the generation \n",
    "from tqdm import trange\n",
    "c_ghost = np.zeros((1, )+ (64,64)+(OUT_DIMS,))\n",
    "c_ghost[:, c_ghost.shape[1]//2, c_ghost.shape[2]//2, 3:]=1\n",
    "c_emoji = np.zeros((1, )+ (40,40)+(OUT_DIMS,))\n",
    "c_emoji[:, c_emoji.shape[1]//2, c_emoji.shape[2]//2, 3:]=1\n",
    "\n",
    "for j in trange(N[-1]):\n",
    "    fig, axss = plt.subplots(2, 3, dpi=100, figsize=(13,8))\n",
    "    c_ghost = m_ghost(c_ghost)\n",
    "    c_emoji = m_emoji(c_emoji)\n",
    "    for c, axs in zip([c_ghost, c_emoji], axss):\n",
    "        visible = c[:,:,:,0:4].numpy()\n",
    "        visible = visible.clip(0,1)\n",
    "        axs[0].imshow(visible[0])\n",
    "        axs[0].set_title(\"with predicted $\\\\alpha$\")\n",
    "        visible[:,:,:,3] = visible[:,:,:,3].round().clip(0,1)\n",
    "        axs[1].set_title(\"with binary $\\\\alpha$ ($\\\\alpha < 0.1$ means dead)\")\n",
    "        axs[1].imshow(visible[0])\n",
    "        axs[2].set_title(\"ignoring $\\\\alpha$\")\n",
    "        axs[2].imshow(visible[0,:,:,0:3])\n",
    "        axs[0].set_xticks([])\n",
    "        axs[1].set_xticks([])\n",
    "        axs[2].set_xticks([])\n",
    "        axs[0].set_yticks([])\n",
    "        axs[1].set_yticks([])\n",
    "        axs[2].set_yticks([])\n",
    "    fig.suptitle(\"Growing Neural Cellular Automata\", fontsize=24, y=0.97)\n",
    "    plt.savefig(f'imgs/{j}.png')\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (ML lib metal)",
   "language": "python",
   "name": "ml-apple-metal-3-10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
